{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SR-qZSgt7Kx6"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys"
      ],
      "metadata": {
        "id": "PTbbe6YlAtSl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sys.path.append('/content/drive/MyDrive')\n",
        "import statistics\n",
        "import numpy as np\n",
        "import importlib\n",
        "import fncs\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "importlib.reload(fncs)\n",
        "from scipy import stats as st\n",
        "import pandas as pd\n",
        "from keras.utils import to_categorical\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten, Reshape\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Conv1D\n",
        "from keras.layers import MaxPooling1D\n",
        "from keras.optimizers import SGD, Adam, RMSprop\n",
        "from keras.layers import Dropout, InputLayer, LSTM\n",
        "from keras.layers import Bidirectional, BatchNormalization\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.layers import Conv1D, AveragePooling1D, Dropout, UpSampling1D, BatchNormalization, LeakyReLU\n",
        "from keras import regularizers"
      ],
      "metadata": {
        "id": "7BqaIGssAxd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def makeXandY(xt, xv, yt, yv):\n",
        "  count = 0\n",
        "  xLabels = []\n",
        "  for i in range(len(yt)):\n",
        "    while((count <= len(xt)) and (xt[count] <= yt[i])):\n",
        "      xLabels.append(yv[i])\n",
        "      count+=1\n",
        "\n",
        "\n",
        "  dfxv = pd.DataFrame(xv)\n",
        "  dfxLabel = pd.DataFrame(xLabels)\n",
        "\n",
        "  xandy = pd.concat([dfxv, dfxLabel], axis = 1)\n",
        "\n",
        "  xandy = xandy.dropna()\n",
        "\n",
        "\n",
        "  return xandy\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "T9vFT599mzop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loadFeatures(dataFolder,idList):\n",
        "    df = None\n",
        "    for k,id in enumerate(idList):\n",
        "        # Loading the raw data\n",
        "        xt, xv, yt, yv = fncs.loadTrial(dataFolder,id=id)\n",
        "        tempDf = makeXandY(xt, xv, yt, yv)\n",
        "        if df is None:\n",
        "          df = tempDf\n",
        "        else:\n",
        "          df = pd.concat([df, tempDf], ignore_index=True)\n",
        "\n",
        "\n",
        "    return df.values[:, :6], df.values[:, 6]"
      ],
      "metadata": {
        "id": "oszzsbu8BVC3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "dirTrain = '/content/drive/MyDrive/train/train/'\n",
        "\n",
        "valIDs = [11,1,15]\n",
        "trainIDs = list(set(np.array(range(29))+1).difference(valIDs))\n",
        "\n",
        "xTrain, yTrain = loadFeatures(dirTrain, trainIDs)\n",
        "xVal, yVal = loadFeatures(dirTrain, valIDs)"
      ],
      "metadata": {
        "id": "zO0PLojTBzsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encoding(y):\n",
        "  return to_categorical(y, num_classes=4).reshape(-1,4)\n",
        "\n",
        "def normalize(x):\n",
        "  scaler = StandardScaler()\n",
        "  return scaler.fit_transform(x)\n"
      ],
      "metadata": {
        "id": "9E11eTF2Izo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xTrain = normalize(xTrain)\n",
        "xVal = normalize(xVal)\n"
      ],
      "metadata": {
        "id": "P-nxpe8IKoB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yTrain = encoding(yTrain)\n",
        "yVal = encoding(yVal)"
      ],
      "metadata": {
        "id": "eLrvgkgrN1O5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def windowDefinition(windowSize, x, y):\n",
        "  windowX = [x[i:i+windowSize] for i in range(0, len(x)-windowSize, windowSize+1)]\n",
        "  windowY = [y[i:i+windowSize] for i in range(0, len(y)-windowSize, windowSize+1)]\n",
        "\n",
        "  windowX = np.array(windowX).reshape(-1, windowSize, 6)\n",
        "  windowY = np.array(windowY).reshape(-1, windowSize, 4)\n",
        "\n",
        "  return windowX, windowY\n"
      ],
      "metadata": {
        "id": "-dvDSGdpQArU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xTrain, yTrain = windowDefinition(40, xTrain, yTrain)\n",
        "xVal, yVal = windowDefinition(40, xVal, yVal)\n",
        "\n",
        "xTrain.shape\n"
      ],
      "metadata": {
        "id": "JkfwloWJUpZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yTrain.shape"
      ],
      "metadata": {
        "id": "EDcwuphjVJO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(xTrain.shape, yTrain.shape, xVal.shape, yVal.shape)"
      ],
      "metadata": {
        "id": "yfAeo4WvOAsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yTrain"
      ],
      "metadata": {
        "id": "PHJ1xODqfNW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_1dCNN():\n",
        "  model = Sequential()\n",
        "  model.add(Conv1D(16, kernel_size=3, activation='relu', padding='same', input_shape=(40,6)))\n",
        "\n",
        "  model.add(MaxPooling1D(2))\n",
        "  model.add(Dropout(0.2))\n",
        "\n",
        "  model.add(Conv1D(32, kernel_size=3, activation='relu', padding='same'))\n",
        "  model.add(MaxPooling1D(2))\n",
        "  model.add(Dropout(0.2))\n",
        "\n",
        "  model.add(Conv1D(32, kernel_size=3, activation='relu', padding='same'))\n",
        "  model.add(UpSampling1D(size=2))\n",
        "  model.add(Dropout(0.2))\n",
        "\n",
        "  model.add(Conv1D(16, kernel_size=3, activation='relu', padding='same'))\n",
        "  model.add(UpSampling1D(size=2))\n",
        "  model.add(Dropout(0.2))\n",
        "\n",
        "  model.add(Conv1D(4, kernel_size=3, activation='softmax', padding='same'))\n",
        "  model.compile(optimizer=Adam(learning_rate=0.001),  loss='categorical_crossentropy', metrics = ['accuracy'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "diS0PSyzVNBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_1dCNN()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "y9zEyJ6PVTTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_fit = model.fit(xTrain, yTrain, epochs=20, verbose=1, validation_data=(xVal, yVal))"
      ],
      "metadata": {
        "id": "X83G8l_xVUBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dirTest = '/content/drive/MyDrive/train/test/'"
      ],
      "metadata": {
        "id": "Opxtf5aHqnhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def testWindows(testX, windowSize):\n",
        "    windowX = [testX[i:i+windowSize] for i in range(0, len(testX)-windowSize+1, windowSize)]\n",
        "\n",
        "    if len(testX) % windowSize != 0:\n",
        "        windowX.append(testX[-windowSize:])\n",
        "\n",
        "    windowX = np.array(windowX).reshape(-1, windowSize, 6)\n",
        "    return windowX\n"
      ],
      "metadata": {
        "id": "Xj6dIgqGtDNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def makeFinalRes(testxt, testxv, testyt, testyv):\n",
        "  count = 0\n",
        "  predictionsFinal = [0 for i in range(len(testyt))]\n",
        "  for i in range(len(testyt)):\n",
        "    vals = []\n",
        "    while(count<len(testxt) and (testxt[count] <= testyt[i])):\n",
        "      vals.append(testyv[count])\n",
        "      count+=1\n",
        "\n",
        "    if len(vals) == 0:\n",
        "      predictionsFinal[i] = predictionsFinal[i-1]\n",
        "\n",
        "    else:\n",
        "      predictionsFinal[i] = statistics.mode(vals)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  return np.array(predictionsFinal)\n"
      ],
      "metadata": {
        "id": "9P6xMy05rDji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def saveArraysAsCSV(array1, array2, filename):\n",
        "    structuredArray = np.column_stack((array1, array2))\n",
        "\n",
        "    np.savetxt(filename, structuredArray, delimiter=',')"
      ],
      "metadata": {
        "id": "Wm8OC2pKuPIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ids = [1,2,3,4]\n",
        "finalPath = '/content/drive/MyDrive/ans/'\n",
        "for id in ids:\n",
        "  testxt, testxv, testyt, testyv = fncs.loadTrial(dirTest, id)\n",
        "  testxv = normalize(testxv)\n",
        "  testxv = testWindows(testxv, 40)\n",
        "  testyv = model.predict(testxv)\n",
        "  testyv = testyv.reshape(-1,4)\n",
        "  testyv = testyv[:len(testxt)]\n",
        "  testyv = np.argmax(testyv, axis = 1)\n",
        "  finalPred = makeFinalRes(testxt, testxv, testyt, testyv)\n",
        "  nameOfCSV = \"Trial0\" + str(id) + \"_y.csv\"\n",
        "  saveArraysAsCSV(testyt, finalPred, finalPath + nameOfCSV)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "neDqLgn3sJkW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}